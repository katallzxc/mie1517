{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Data_Visualization_Preprocessing_Binary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2387cbef"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import tarfile\n",
        "import matplotlib.image as image\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "2387cbef",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6da757"
      },
      "source": [
        "labels_encoder = {0: \"Neutral\", 1: \"Happy\", 2: \"Sad\", 3:\"Surprise\", \n",
        "                  4: \"Fear\", 5: \"Disgust\", 6: \"Anger\", 7: \"Contempt\"}\n",
        "\n",
        "labels_encoder_binary = {0: \"Non-Happy\", 1: \"Happy\"}"
      ],
      "id": "dd6da757",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-AhZaOy1N5N",
        "outputId": "d71b081c-0fbe-4141-c7e7-a7f647c13849"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "id": "I-AhZaOy1N5N",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SbE96RUEcIB"
      },
      "source": [
        "def unzip_tar_file(source_path,destination_path):\n",
        "    '''\n",
        "    Read contents of .tar file into memory in Google Colab.\n",
        "    '''\n",
        "    zip_ref = tarfile.TarFile(source_path, 'r') \n",
        "    zip_ref.extractall(destination_path) \n",
        "    zip_ref.close()\n",
        "\n",
        "def load_images_from_folder(folder,s,cnn = False):\n",
        "    '''\n",
        "    Read data images and their expression label (integer) in from folder.\n",
        "    '''\n",
        "    # get list of image filenames\n",
        "    images = []\n",
        "    labels = []\n",
        "    imagefolder = folder+'/images'\n",
        "    k = os.listdir(imagefolder)[:s]\n",
        "    \n",
        "    # read in all images and labels from folder\n",
        "    for filename in k:\n",
        "        # add image to list\n",
        "        img = plt.imread(os.path.join(folder+'/images',filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "        \n",
        "        # get filename for label for this image ('exp' files give expression label as int)\n",
        "        number = int(re.search(r'\\d+',  filename)[0])\n",
        "        label_filename = folder+'/annotations/'+str(number)+'_exp.npy'\n",
        "        \n",
        "        # get expression label and add to list, or label as \"not face\" and warn if label not found\n",
        "        if os.path.isfile(label_filename):\n",
        "            label = np.load(label_filename)\n",
        "        else:\n",
        "            label = 10\n",
        "            print(\"Label for image %s not found\"%filename)\n",
        "        labels.append(int(label))\n",
        "        \n",
        "    images = np.array(images)\n",
        "    print(\"Shape of images is \",np.shape(images))\n",
        "    labels = np.array(labels)\n",
        "    print(\"Shape of labels is \",np.shape(labels))\n",
        "    \n",
        "    if cnn:\n",
        "      images = np.transpose(torch.tensor(images),[0,3,2,1])\n",
        "      trainfeature= resnet(images/255)\n",
        "      trainfeature = [x.clone().detach() for x in trainfeature]\n",
        "      data = zip(trainfeature, labels)\n",
        "      data = list(data)\n",
        "    \n",
        "    else:\n",
        "      images = np.transpose(torch.tensor(images),[0,3,2,1])\n",
        "      images = images/255\n",
        "      images = [x.clone().detach() for x in images]\n",
        "      data = zip(images, labels)\n",
        "      data =  list(data)\n",
        "    \n",
        "    return data,images"
      ],
      "id": "2SbE96RUEcIB",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruizbprgEfHY",
        "outputId": "05df6c12-cca1-4bd9-f1ff-3590c15886b1"
      },
      "source": [
        "train_path = '/content/gdrive/MyDrive/Colab Notebooks/Project/data/train_set.tar'\n",
        "valid_path = '/content/gdrive/MyDrive/Colab Notebooks/Project/data/val_set.tar'\n",
        "unzip_tar_file(train_path, '/content') \n",
        "unzip_tar_file(valid_path, '/content') \n",
        "\n",
        "traindata = load_images_from_folder('train_set',4000,cnn = False)\n",
        "print(\"Shape of training data: \")\n",
        "print(np.shape(traindata))\n",
        "\n",
        "valdata = load_images_from_folder('val_set',400,cnn = False)\n",
        "print(\"Shape of validation data: \")\n",
        "print(np.shape(valdata))"
      ],
      "id": "ruizbprgEfHY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images is  (4000, 224, 224, 3)\n",
            "Shape of labels is  (4000,)\n",
            "Shape of training data: \n",
            "(2, 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images is  (400, 224, 224, 3)\n",
            "Shape of labels is  (400,)\n",
            "Shape of validation data: \n",
            "(2, 400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P43od8k0CfGv"
      },
      "source": [
        "def make_labelled_dataframe(path,lbl_extension,img_extension):\n",
        "    '''\n",
        "    Imports all images and labels from directory \"path\" to annotation (label)\n",
        "    information and makes dataframe with all image filenames and their labels\n",
        "    '''\n",
        "    # add all filenames and labels to list\n",
        "    labels_data = []\n",
        "    for filename in tqdm(os.listdir(path)):\n",
        "        if filename.endswith('_exp.npy'):\n",
        "            img_filename = filename.replace(lbl_extension,img_extension)\n",
        "            labels_data.append([img_filename, np.load(path+filename).item()])\n",
        "\n",
        "    # convert list to DataFrame   \n",
        "    labels_dataframe = pd.DataFrame(labels_data)\n",
        "    labels_dataframe[1] = labels_dataframe[1].astype('int32')\n",
        "\n",
        "    return labels_dataframe\n",
        "\n",
        "def make_binary_dataframe(labels_dataframe,happy_ind_int,nonhappy_ind_list):\n",
        "    '''\n",
        "    Takes in dataframe with all filenames and labels and splits into equally sized\n",
        "    happy and non-happy dataframes, then reassigns labels as 0=nonhappy, 1=happy and\n",
        "    concatenates to make a binary dataframe.\n",
        "    '''\n",
        "    # get N, min number of training samples that have happy vs unhappy faces\n",
        "    num_happy = np.count_nonzero(labels_dataframe[1] == happy_ind_int)\n",
        "    num_nonhappy = np.count_nonzero(labels_dataframe[1] != happy_ind_int)\n",
        "    min_num = min(num_happy,num_nonhappy)\n",
        "\n",
        "    #print(num_happy)\n",
        "    #print(num_nonhappy)\n",
        "\n",
        "    # get N happy samples\n",
        "    happy_mask = labels_dataframe[1]==happy_ind_int\n",
        "    happy_df = labels_dataframe[happy_mask].sample(frac=1).iloc[:min_num]\n",
        "    #print(happy_df.info())\n",
        "\n",
        "    # get all unhappy samples, limit to N samples, and set new label to 0\n",
        "    nonhappy_mask = labels_dataframe[1].isin(nonhappy_ind_list)\n",
        "    nonhappy_df = labels_dataframe[nonhappy_mask].sample(frac=1).iloc[:min_num]\n",
        "    nonhappy_df[1] = 0\n",
        "    #print(nonhappy_df.info())\n",
        "\n",
        "    # create a balanced dataframe\n",
        "    balanced_dataframe = pd.concat([happy_df,nonhappy_df])\n",
        "    print(balanced_dataframe.info())\n",
        "    #print(balanced_dataframe)\n",
        "\n",
        "    return balanced_dataframe"
      ],
      "id": "P43od8k0CfGv",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5efd8b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0262ff1a-d3e8-48e0-f59d-d511a9cb412e"
      },
      "source": [
        "# train set data visualization\n",
        "train_dir = 'train_set/annotations/'\n",
        "labels_df = make_labelled_dataframe(train_dir,'_exp.npy','.jpg')\n",
        "print(labels_df.info())\n",
        "\n",
        "# plot data architecture before binarization\n",
        "sns.countplot(labels_df[1].map(labels_encoder))"
      ],
      "id": "5efd8b94",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 422988/1150604 [01:50<03:07, 3884.76it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6cd4161"
      },
      "source": [
        "index_happy = 1\n",
        "indices_nonhappy = [0,2,3,4,5,6,7]\n",
        "balanced_df = make_binary_dataframe(labels_df,index_happy,indices_nonhappy)\n",
        "\n",
        "# plot data architecture after binarization\n",
        "sns.countplot(balanced_df[1].map(labels_encoder_binary))"
      ],
      "id": "d6cd4161",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678bbff8"
      },
      "source": [
        "balanced_df.to_csv(train_dir+'labels.csv', index=False)\n",
        "print(\"labels.csv created at \"+train_dir)"
      ],
      "id": "678bbff8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5934bba"
      },
      "source": [
        "# valid set data visualization\n",
        "#labels_dir = './data/val_set/annotations/'\n",
        "valid_dir = 'val_set/annotations/'\n",
        "labels_df = make_labelled_dataframe(valid_dir,'_exp.npy','.jpg')\n",
        "print(labels_df.info())\n",
        "\n",
        "# plot data architecture before binarization\n",
        "sns.countplot(labels_df[1].map(labels_encoder))"
      ],
      "id": "c5934bba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88fbb91d"
      },
      "source": [
        "balanced_df = make_binary_dataframe(labels_df,index_happy,indices_nonhappy)\n",
        "\n",
        "# plot data architecture after binarization\n",
        "sns.countplot(balanced_df[1].map(labels_encoder_binary))"
      ],
      "id": "88fbb91d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2150caf"
      },
      "source": [
        "balanced_df.to_csv(valid_dir+'labels.csv', index=False)\n",
        "print(\"labels.csv created at \"+valid_dir)"
      ],
      "id": "e2150caf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU5U3K11KfhC"
      },
      "source": [
        "!cp \"train_set/annotations/labels.csv\" \"/content/gdrive/MyDrive/Colab Notebooks/Project/data/train_labels.csv\"\n",
        "!cp \"val_set/annotations/labels.csv\" \"/content/gdrive/MyDrive/Colab Notebooks/Project/data/val_labels.csv\""
      ],
      "id": "FU5U3K11KfhC",
      "execution_count": null,
      "outputs": []
    }
  ]
}