{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e7e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision.models\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7617ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class HappyFaceClassifier_alex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HappyFaceClassifier_alex, self).__init__()\n",
    "        self.name = \"HFC_alex\"\n",
    "        self.fc1 = nn.Linear(256*6*6, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.squeeze(1) # Flatten to [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8689f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Happy_Face_Recog(image_path, model_path):\n",
    "    # define image\n",
    "    image = read_image(image_path)\n",
    "    # resize image to fit model (3x224x224)\n",
    "    transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.Grayscale(3)])\n",
    "    image = transform(image).unsqueeze(dim=0)\n",
    "    \n",
    "    # define models\n",
    "    model = HappyFaceClassifier_alex()\n",
    "    pretrained_model = torchvision.models.alexnet(pretrained=True)\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state)\n",
    "    \n",
    "    # feature extraction\n",
    "    features = pretrained_model.features(image/255)\n",
    "    # model prediction\n",
    "    output = model(features)\n",
    "    pred = (output > 0.0).squeeze().long()\n",
    "    if pred == 1:\n",
    "        print (\"The person is happy.\")\n",
    "        return True\n",
    "    else:\n",
    "        print (\"The person is not happy.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41503285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/happy_face_1.jpg'\n",
    "# selected model weights\n",
    "model_path = './weights/model_HFC_alex_bs512_lr0.005_epoch5'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c898e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/happy_face_3.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf7f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/happy_face_4.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd3884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/happy_face_5.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62287590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is not happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/sad_face_1.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06dd1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is not happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/sad_face_2.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f23b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is not happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/sad_face_3.png'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6341f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is not happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/sad_face_4.png'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307ab14",
   "metadata": {},
   "source": [
    "WRONG CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33d304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is not happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/happy_face_2.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "539d381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is happy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: image directory\n",
    "image_path = './examples/angry_face_1.jpg'\n",
    "\n",
    "# display image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "\n",
    "# Apply happy face recognition\n",
    "Happy_Face_Recog(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a10411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
